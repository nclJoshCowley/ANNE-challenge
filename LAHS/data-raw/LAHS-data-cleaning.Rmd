---
title: "LAHS Data Cleaning Script"
author: "Josh Cowley"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
params:
  use_data: TRUE
---

```{r setup, include = FALSE}
# CRAN
library(tidyverse)
library(usethis)
library(kableExtra)

# Github
library(LAHS)
LAHS::common_report_setup(echo = TRUE)

# Hooks
knitr::knit_hooks$set(source = LAHS::get_knit_hook_source_hide())
```

The purpose of this report is to convey all processes used and any decisions
made when the data was cleaned.
The source of this data (CSV) can be found at
<https://www.gov.uk/government/statistical-data-sets/local-authority-housing-statistics-open-data>.

Currently, we are interested in a subset of these data and as such will 
populate a new data frame as we clean the data.

```{r load-csv}
lahs_path <-
  file.path("data-raw", "LAHS_201112_to_202021_open_data_02_2022.csv")

lahs_csv <- utils::read.csv(lahs_path)

LAHS <- tibble::tibble(.rows = nrow(lahs_csv))
```

# Local Authority Information

## Unique Identifiers

We use the local authority code and name at the time of data collection,
ignoring the codes and names using the 2020 geography

```{r add-la-code-name}
LAHS$LA_CODE <- lahs_csv$LA_CODE
LAHS$LA_NAME <- lahs_csv$LA_NAME
```

There are `r length(unique(LAHS$LA_NAME))` unique local authorities.
Most have 10 data points, one for each year, but this is not always the case.
The following visualisation summarises the LA(s) that have fewer than 10 
observations.

```{r plot-la-code-name-issues, hide = "Reveal ggplot2 code."}
LAHS %>%
  dplyr::count(.data$LA_NAME) %>%
  dplyr::filter(.data$n != 10) %>%
  ggplot2::ggplot(ggplot2::aes(
    y = forcats::fct_rev(factor(.data$LA_NAME)),
    xmax = .data$n,
  )) +
  ggplot2::geom_linerange(xmin = 0) +
  ggplot2::scale_x_continuous(breaks = 1:10, limits = c(1, 10)) +
  ggplot2::labs(y = NULL, x = "Number of Datum")
```

For now, we mark these problematic LA(s) for removal but may revisit these 
issues to increase the data available.

```{r mark-rm-la-name, echo = FALSE}
REMOVALS_LA_NAME <-
  local({
    tbl <- table(LAHS$LA_NAME)
    names(tbl)[tbl != 10]
  })
```

## Classification

We are also interested in the categorical information that is held in the first 
three characters of the local authority code and in its own column.

For example, Darlington is coded "E06000005"; the "E06" implies that this LA
is a unitary authority. We convert each code to a corresponding label.

```{r add-la-type}
LAHS$LA_TYPE <- LAHS::LAD20TYPE_to_label(lahs_csv$LAD20TYPE)
```

We can see the respective sample sizes of such divisions here.

```{r show-la-type, hide = "Reveal table generating code."}
dplyr::count(LAHS, .data$LA_TYPE) %>%
  kableExtra::kbl(col.names = c("Local Authority Type", "N"), align = "lc") %>%
  kableExtra::kable_styling()
```

A further classification can be made on the region each LA exists in.

```{r add-la-region}
LAHS$LA_REGION <- lahs_csv$RGN20NM
```

With a similar table also made.

```{r show-la-region, hide = "Reveal table generating code."}
dplyr::count(LAHS, .data$LA_REGION) %>%
  kableExtra::kbl(col.names = c("English Region", "N"), align = "lc") %>%
  kableExtra::kable_styling()
```

# Temporal Information

The raw data spans a decade and lists the years in plain text, that is, 
"2011-12", "2012-13" to "2020-21".
To convert this to numerical information we obtain the data as year start 
information so a value of $20$ denotes the duration from tax year start, 2020,
to tax year end, 2021.

```{r add-year}
LAHS$YEAR <- 
  lahs_csv$Year %>%
  regmatches(regexpr("^20[0-9]{2}", .)) %>%
  as.integer()
```









# Access to these Data

```{r use-data, echo = FALSE, eval = params$use_data}
usethis::use_data(LAHS, overwrite = TRUE)
```

One can access this data by installing this package and importing the `LAHS` 
dataset in the following way.

```{r eg-import, echo = TRUE, eval = FALSE}
data("LAHS", package = "LAHS")
```
